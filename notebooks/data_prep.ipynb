{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import embedding_functions\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data import\n",
    "data_path = './../data/raw/20news-bydate/20news-bydate-train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of category directories\n",
    "categories = [d for d in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, d))]\n",
    "\n",
    "# create lists to store texts and corresponding categories\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "# Loop through each category directory to read the text files and assign the appropriate label.\n",
    "for category in categories:\n",
    "    category_path = os.path.join(data_path, category)\n",
    "\n",
    "    # import all text files in the current category folder\n",
    "    file_paths = glob.glob(os.path.join(category_path, '*'))\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            text = file.read()\n",
    "            texts.append(text)\n",
    "            labels.append(category)\n",
    "\n",
    "# create data frame\n",
    "df = pd.DataFrame({'text': texts, 'category': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "\n",
    "for idx, text in enumerate(df['text']):\n",
    "    try:\n",
    "        embedding = get_embedding(text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating embedding for index {idx}: {e}\")\n",
    "    \n",
    "    embeddings.append(embedding)\n",
    "\n",
    "    # if necessary ... short delay to avoid API rate limits\n",
    "    # time.sleep(0.1)\n",
    "\n",
    "# add embeddings to data frame\n",
    "df['embedding'] = embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-Import Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./../data/processed/train_with_embeddings.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conduct Principal Component Analysis\n",
    "\n",
    "First, convert embeddings to a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_array = np.array(df['embedding'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, initialize and fit PCA to reduce to 2 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_2d = PCA(n_components=2)\n",
    "\n",
    "components = pca_2d.fit_transform(embedding_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the new components as X and Y columns in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x_2d'] = components[:, 0]\n",
    "df['y_2d'] = components[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, repeat PCA but for 3 dimensions, and add those to the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_3d = PCA(n_components=3)\n",
    "\n",
    "components = pca_3d.fit_transform(embedding_array)\n",
    "\n",
    "df['x_3d'] = components[:, 0]\n",
    "df['y_3d'] = components[:, 1]\n",
    "df['z_3d'] = components[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the final data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data frame as pickle file in 'processed' folder\n",
    "df.to_pickle('./../data/processed/train_with_embeddings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
